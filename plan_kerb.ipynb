{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib\n",
    "from scrapy.http import TextResponse\n",
    "import requests\n",
    "\n",
    "# r = urllib.urlopen('https://www.kerbfood.com/markets/west-india-quay/').read()\n",
    "# soup = BeautifulSoup(r)\n",
    "\n",
    "kerb_req = requests.get('https://www.kerbfood.com/markets/west-india-quay/')\n",
    "response = TextResponse(kerb_req.url, body=kerb_req.text, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thursday 5th September',\n",
       " 'Friday 6th September',\n",
       " 'Monday 9th September',\n",
       " 'Tuesday 10th September',\n",
       " 'Wednesday 11th September',\n",
       " 'Thursday 12th September',\n",
       " 'Friday 13th September',\n",
       " 'Monday 16th September',\n",
       " 'Tuesday 17th September',\n",
       " 'Wednesday 18th September',\n",
       " 'Thursday 19th September',\n",
       " 'Friday 20th September',\n",
       " 'Monday 23rd September',\n",
       " 'Tuesday 24th September',\n",
       " 'Wednesday 25th September',\n",
       " 'Thursday 26th September',\n",
       " 'Friday 27th September',\n",
       " 'Monday 30th September']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dates from website\n",
    "dates_xpath = response.xpath('//*[@class=\"rsCaption\"]/text()')\n",
    "dates = dates_xpath.getall()\n",
    "dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 9, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse dates\n",
    "import dateutil\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "def parse_date(date_string):\n",
    "    return dateutil.parser.parse(date_string).date()\n",
    "\n",
    "def after_today(compare_date):\n",
    "    return compare_date > datetime.today().date()\n",
    "\n",
    "def before_today(compare_date):\n",
    "    return compare_date < datetime.today().date()\n",
    "\n",
    "def after_date(compare_date, after_date):\n",
    "    return compare_date > after_date\n",
    "\n",
    "def before_date(compare_date, before_date):\n",
    "    return compare_date < before_date\n",
    "\n",
    "def end_of_this_week():\n",
    "    today = datetime.today().weekday()\n",
    "    days_til_eow = 6 - today\n",
    "    return datetime.today().date() + timedelta(days=days_til_eow)\n",
    "\n",
    "def end_of_week(from_date):\n",
    "#     today = date.today().weekday()\n",
    "    day = from_date.weekday()\n",
    "    days_til_eow = 6 - day # if day < 6 else day\n",
    "    return from_date + timedelta(days=days_til_eow)\n",
    "    \n",
    "end_of_week(date(2019, 9, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Friday 6th September']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dates only take those between now and end of week\n",
    "\n",
    "this_week_dates = [date for date in dates if after_today(parse_date(date)) and before_date(parse_date(date), end_of_this_week())]\n",
    "this_week_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday 6th September': ['Baggio Burger',\n",
       "  'Komex Kitchen',\n",
       "  'Lovely Bunch of Coconuts',\n",
       "  'Makatcha',\n",
       "  'Mother Flipper',\n",
       "  'Nazari',\n",
       "  'The Beefsteaks',\n",
       "  'The Grilling Greek',\n",
       "  'The Patate',\n",
       "  'Mexikings',\n",
       "  'Hanoi Kitchen']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_day_traders(day):\n",
    "    return response.xpath('//*[@class=\"rsCaption\"][text()=\"{}\"]/following-sibling::div[contains(@class, \"row\")]/div[contains(@class, \"grid-item\")]//span[contains(@class, \"bolder\")]/text()'.format(day)).getall()\n",
    "# len(grid_items_xpath)\n",
    "\n",
    "traders = {}\n",
    "for day in this_week_dates:\n",
    "    day_traders = get_day_traders(day)\n",
    "    traders[day] = day_traders\n",
    "    \n",
    "traders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to Mother Flipper\n",
      " on Friday 6th September\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "kerb_days = 2 # CHANGE THIS NUMBER FOR HOW MANY DAYS YOU WANNA KERB\n",
    "\n",
    "\n",
    "try:\n",
    "    random_date_no = random.sample(range(1, len(this_week_dates)), kerb_days) if len(this_week_dates) > 1 else [len(this_week_dates)]\n",
    "except:\n",
    "    print(\"Kerb isn't on that many days.....\")\n",
    "    random_date_no = random.sample(range(1, len(this_week_dates)), len(this_week_dates))\n",
    "\n",
    "for date_no in random_date_no:\n",
    "    chosen_date = this_week_dates[date_no - 1]\n",
    "    date_traders = traders[chosen_date]\n",
    "    \n",
    "    random_trader_no = random.randint(1, len(date_traders))\n",
    "    print('Go to {}\\n on {}'.format(date_traders[random_trader_no - 1], chosen_date))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kerb for the Week:\n",
      "Thursday 5th September: Cally Munchy\n",
      "Friday 6th September: Nazari\n",
      "Monday 9th September: Ugly Duck\n",
      "Tuesday 10th September: Yaay Yaay\n",
      "Wednesday 11th September: Turo Turo\n",
      "Thursday 12th September: Meltsmiths\n",
      "Friday 13th September: Nazari\n",
      "Monday 16th September: Ugly Duck\n",
      "Tuesday 17th September: Lagniappe Trini Kitchen\n",
      "Wednesday 18th September: Carcass\n",
      "Thursday 19th September: Meltsmiths\n",
      "Friday 20th September: Makatcha\n",
      "Monday 23rd September: Utter Waffle\n",
      "Tuesday 24th September: Tribeca Deli\n",
      "Wednesday 25th September: Rice Guys\n",
      "Thursday 26th September: Meltsmiths\n",
      "Friday 27th September: The Patate\n",
      "Monday 30th September: Ugly Duck\n"
     ]
    }
   ],
   "source": [
    "print('Kerb for the Week:')\n",
    "kerb_days = 2\n",
    "for date in dates:\n",
    "    daily = response.xpath('//*[@class=\"rsCaption\"][text()=\"{}\"]/following-sibling::div[contains(@class, \"row\")]/div[contains(@class, \"grid-item\")]'.format(date))\n",
    "    daily_traders = daily.xpath('.//span[contains(@class, \"bolder\")]/text()').getall()\n",
    "    daily_random_trader = random.randint(1, len(daily_traders))\n",
    "    print('{}: {}'.format(date, daily_traders[daily_random_trader-1]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
